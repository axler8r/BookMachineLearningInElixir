<!-- livebook:{"persist_outputs":true} -->

# Machine Learning in Elixir â€” Chapter 1

```elixir
Mix.install(
  [ {:axon, "~> 0.6"},
    {:nx, "~> 0.7"},
    {:torchx, "~> 0.7"},
    # {:exla, "~> 0.7"},
    {:explorer, "~> 0.8"},
    {:kino, "~> 0.13"}
  ]
  # system_env: %{"LIBTORCH_TARGET" => "cu122"}
  # config: [nx: [default_backend: {EXLA.Backend, device: :cuda}]]
)

```

## Example of an Axon Workflow

Make sure you can access the appropriate modules.

```elixir
require Explorer.DataFrame, as: DF

```

<!-- livebook:{"output":true} -->

```
Explorer.DataFrame
```

Set the global backend to use CUDA

```elixir
Nx.global_default_backend(Torchx.Backend)

```

<!-- livebook:{"output":true} -->

```
{Nx.BinaryBackend, []}
```

Get data

```elixir
iris = Explorer.Datasets.iris()

```

<!-- livebook:{"output":true} -->

```
#Explorer.DataFrame<
  Polars[150 x 5]
  sepal_length f64 [5.1, 4.9, 4.7, 4.6, 5.0, ...]
  sepal_width f64 [3.5, 3.0, 3.2, 3.1, 3.6, ...]
  petal_length f64 [1.4, 1.4, 1.3, 1.5, 1.4, ...]
  petal_width f64 [0.2, 0.2, 0.2, 0.2, 0.2, ...]
  species string ["Iris-setosa", "Iris-setosa", "Iris-setosa", "Iris-setosa", "Iris-setosa", ...]
>
```

Standardise and shuffle data

```elixir
columns = ~W/sepal_width sepal_length petal_length petal_width/
shuffled_standardised_irises =
  iris
  |> DF.mutate(
    for column <- across(^columns) do
      {column.name, (column - mean(column))/variance(column)}
    end
  )
  |> DF.mutate(species: Explorer.Series.cast(species, :category))
  |> DF.shuffle()

```

<!-- livebook:{"output":true} -->

```
#Explorer.DataFrame<
  Polars[150 x 5]
  sepal_length f64 [0.37431689531981416, -0.5007096132200132, 0.6659923981664237,
   -0.6465473646433173, -1.3757361217598405, ...]
  sepal_width f64 [-1.3510348914417085, -2.946745393144513, -2.946745393144513, 1.8403861119639024,
   -3.4786488937121147, ...]
  petal_length f64 [0.30237040878096977, 0.07751989233619774, 0.3987349158287291,
   -0.6612746616966245, -0.14733062410857428, ...]
  petal_width f64 [0.0022893210088989076, 0.17398839667633603, 1.2041828506809578,
   -1.7147014356654708, -0.341108830325975, ...]
  species category ["Iris-versicolor", "Iris-versicolor", "Iris-virginica", "Iris-setosa",
   "Iris-versicolor", ...]
>
```

Make training and testing sets

```elixir
train_irises = DF.slice(shuffled_standardised_irises, 0..119)
test_irises = DF.slice(shuffled_standardised_irises, 120..149)

```

<!-- livebook:{"output":true} -->

```
#Explorer.DataFrame<
  Polars[30 x 5]
  sepal_length f64 [1.8326944095528606, -0.5007096132200132, -2.2507626302996693,
   -1.0840606189132322, 1.2493434038596427, ...]
  sepal_width f64 [-0.28722789030650403, -2.4148418925769106, -0.28722789030650403,
   2.3722896125315045, 0.2446756102610982, ...]
  petal_length f64 [0.6878284369720075, 0.2060059017332104, -0.8540036757921433,
   -0.7576391687443839, 0.2060059017332104, ...]
  petal_width f64 [1.547581002015832, 0.0022893210088989076, -1.8864005113329076,
   -1.5430023599980338, 0.3456874723437728, ...]
  species category ["Iris-virginica", "Iris-versicolor", "Iris-setosa", "Iris-setosa",
   "Iris-versicolor", ...]
>
```

Extract $\hat{y}_{train}$ and $\hat{y}_{test}$

```elixir
features = ~W/sepal_width sepal_length petal_length petal_width/
x_train = Nx.stack(train_irises[features], axis: -1)
y_train =
  train_irises["species"]
  |> Nx.stack(axis: -1)
  |> Nx.equal(Nx.iota({1, 3}, axis: -1))
x_test = Nx.stack(test_irises[features], axis: -1)
y_test =
  test_irises["species"]
  |> Nx.stack(axis: -1)
  |> Nx.equal(Nx.iota({1, 3}, axis: -1))

```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  u8[30][3]
  Torchx.Backend(cpu)
  [
    [0, 0, 1],
    [0, 1, 0],
    [1, 0, 0],
    [1, 0, 0],
    [0, 1, 0],
    [1, 0, 0],
    [0, 0, 1],
    [0, 1, 0],
    [0, 0, 1],
    [1, 0, 0],
    [1, 0, 0],
    [1, 0, 0],
    [0, 1, 0],
    [0, 1, 0],
    [0, 1, 0],
    [1, 0, 0],
    [1, 0, ...],
    ...
  ]
>
```

Create a model

```elixir
model =
  Axon.input("iris_features", shape: {nil, 4})
  |> Axon.dense(3, activation: :softmax)

```

<!-- livebook:{"output":true} -->

```
#Axon<
  inputs: %{"iris_features" => {nil, 4}}
  outputs: "softmax_0"
  nodes: 3
>
```

Display the model

```elixir
model |> Axon.Display.as_graph(Nx.template({1, 4}, :f32))

```

Prepare a data stream

```elixir
data_stream = Stream.repeatedly(fn -> {x_train, y_train} end)

```

<!-- livebook:{"output":true} -->

```
#Function<53.38948127/2 in Stream.repeatedly/1>
```

Train the model

```elixir
trained_model =
  model
  |> Axon.Loop.trainer(:categorical_cross_entropy, :sgd)
  |> Axon.Loop.metric(:accuracy)
  |> Axon.Loop.run(data_stream, %{}, iterations: 500, epochs: 10)

```

<!-- livebook:{"output":true} -->

```
Epoch: 0, Batch: 450, accuracy: 0.8020530 loss: 0.5236083
Epoch: 1, Batch: 450, accuracy: 0.8662046 loss: 0.4303810
Epoch: 2, Batch: 450, accuracy: 0.8837752 loss: 0.3856469
Epoch: 3, Batch: 450, accuracy: 0.8916645 loss: 0.3559958
Epoch: 4, Batch: 450, accuracy: 0.8961533 loss: 0.3337785
Epoch: 5, Batch: 450, accuracy: 0.9200444 loss: 0.3160645
Epoch: 6, Batch: 450, accuracy: 0.9285637 loss: 0.3014029
Epoch: 7, Batch: 450, accuracy: 0.9349227 loss: 0.2889582
Epoch: 8, Batch: 450, accuracy: 0.9416718 loss: 0.2781995
Epoch: 9, Batch: 450, accuracy: 0.9416718 loss: 0.2687656
```

<!-- livebook:{"output":true} -->

```
%{
  "dense_0" => %{
    "bias" => #Nx.Tensor<
      f32[3]
      Torchx.Backend(cpu)
      [-0.4255358576774597, 1.4784705638885498, -1.0529359579086304]
    >,
    "kernel" => #Nx.Tensor<
      f32[4][3]
      Torchx.Backend(cpu)
      [
        [0.6292438507080078, -0.2771281898021698, -0.46242883801460266],
        [-1.2461543083190918, 0.28726574778556824, 0.7519252300262451],
        [-1.1918023824691772, 1.0060293674468994, 0.7775965929031372],
        [-1.5709476470947266, -0.7321811318397522, 2.496403455734253]
      ]
    >
  }
}
```

Evaluate the model

```elixir
data = [{x_test, y_test}]
model
|> Axon.Loop.evaluator()
|> Axon.Loop.metric(:accuracy)
|> Axon.Loop.run(data, trained_model)

```

<!-- livebook:{"output":true} -->

```
Batch: 0, accuracy: 1.0000000
```

<!-- livebook:{"output":true} -->

```
%{
  0 => %{
    "accuracy" => #Nx.Tensor<
      f32
      Torchx.Backend(cpu)
      1.0
    >
  }
}
```
